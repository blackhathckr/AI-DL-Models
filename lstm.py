# Long Short Term Memory
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score, f1_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.callbacks import ReduceLROnPlateau, EarlyStopping
from keras.layers import Activation, Dense, Dropout, Embedding, LSTM
import re
from IPython.display import display
import os
import string
import time
import random
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import imdb

(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)
sequence_length = 300

batch_size = 128

X_train_seq = pad_sequences(X_train, maxlen=sequence_length)
X_test_seq = pad_sequences(X_test, maxlen=sequence_length)

encoder = LabelEncoder()
encoder.fit(y_train)
y_train_transformed = encoder.transform(y_train).reshape(-1, 1)
y_test_transformed = encoder.transform(y_test).reshape(-1, 1)

num_words = 5000
e = Embedding(num_words, 10, input_length=sequence_length)

model = Sequential()
model.add(e)
model.add(LSTM(128, dropout=0.25, recurrent_dropout=0.25))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer="adam", loss='binary_crossentropy',metrics=['accuracy'])
early_stopper = EarlyStopping(monitor='val_acc', min_delta=0.0005, patience=3)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, cooldown=0)
callbacks = [reduce_lr, early_stopper]
train_history = model.fit(X_train_seq, y_train_transformed, batch_size=batch_size,epochs=5, validation_split=0.1, verbose=1, callbacks=callbacks)
score = model.evaluate(X_test_seq, y_test_transformed, batch_size=batch_size)

y_pred = model.predict(X_test_seq)

print("Accuracy: {:0.4}".format(score[1]))
print("Loss:", score[0])
print(' Accuracy: { :0.3 }'.format(100*accuracy_score(y_test_transformed, 1 * (y_pred > 0.5))))
print(' f1 score: {:0.3}'.format(100*f1_score(y_test_transformed, 1 * (y_pred > 0.5))))
print(' ROC AUC: {:0.3}'.format(roc_auc_score(y_test_transformed, y_pred)))
print(classification_report(y_test_transformed, 1 * (y_pred > 0.5), digits=3))
